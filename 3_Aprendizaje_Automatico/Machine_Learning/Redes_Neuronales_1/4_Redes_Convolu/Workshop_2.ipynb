{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CV728Zi1PQpn"
      },
      "source": [
        "# Workshop 2: Fundamentals of CNN\n",
        "\n",
        "In this workshop we will learn how to implement a simple Convolutional Neural Netwrok and we will compare it with a Fully Connected Neural Network for the classification of CIFAR10 dataset. The structure of the workshop will be the following:\n",
        "\n",
        "\n",
        "\n",
        "1.   CIFAR10 with Fully Connected Neural Netoworks\n",
        "2.   CIFAR10 with Convolutional Neural Networks\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8oyH11NTAXB"
      },
      "source": [
        "## 1. CIFAR10 with Fully Connected Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxUYGXkFPG98"
      },
      "source": [
        "# Import dependence for downloading CIFAR10\n",
        "from tensorflow import keras\n",
        "from keras.datasets import cifar10 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaGDZgZkS9c1"
      },
      "source": [
        "(X_train, y_train), (X_testval, y_testval) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA-qauKITM-O"
      },
      "source": [
        "# Import dependence for handling arrays\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZZ2TT13TV4H"
      },
      "source": [
        "# Show the shape of the data partitions\n",
        "print(\"X_train original shape:\", X_train.shape)\n",
        "print(\"y_train original shape:\", y_train.shape)\n",
        "print(\"X_testval original shape:\", X_testval.shape)\n",
        "print(\"y_testval original shape:\", y_testval.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7kfUJ2HTdZw"
      },
      "source": [
        "# Show the data type of the data partitions\n",
        "print(\"X_train original dtype:\", X_train.dtype)\n",
        "print(\"y_train original dytpe:\", y_train.dtype)\n",
        "print(\"X_testval original dtype:\", X_testval.dtype)\n",
        "print(\"y_testval original dtype:\", y_testval.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n9ki2vkT5Qm"
      },
      "source": [
        "# Show the data range of the data partitions\n",
        "print(\"X_train original range: [\", X_train.min(), \",\", X_train.max(), \"]\")\n",
        "print(\"X_testval original range: [\", X_train.min(), \",\", X_testval.max(), \"]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9EVn2wBUKBd"
      },
      "source": [
        "# Show the different labels of the data partitions\n",
        "print(\"y_train labels: \\n\", np.unique(y_train))\n",
        "print(\"y_testval labels: \\n\", np.unique(y_testval))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEm7UEoXUUS5"
      },
      "source": [
        "# Import dependence for visualization of images\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = (10,10)  # Configure figure size for \n",
        "                                          # appropriate visualization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlbmE8E0XwA_"
      },
      "source": [
        "def class_to_string(class_int):\n",
        "    classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\",\n",
        "               \"horse\", \"ship\", \"truck\"]\n",
        "    return classes[class_int]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i85MmzL3UYYm"
      },
      "source": [
        "# Show 9 images with its respective ground truth labels\n",
        "for i in range(9):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_train[i], cmap='gray', interpolation='none')\n",
        "    class_str = class_to_string(int(y_train[i]))\n",
        "    plt.title(\"Class: \" + class_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6yqq6lDUakI"
      },
      "source": [
        "# Convert the 2D images to 1D array\n",
        "train_samples = X_train.shape[0]\n",
        "testval_samples = X_testval.shape[0]\n",
        "sample_dims = X_train.shape[1] * X_train.shape[2] * X_train.shape[3]  # 32*32*3\n",
        "X_train_rs = X_train.reshape(train_samples, sample_dims)\n",
        "X_testval_rs = X_testval.reshape(testval_samples, sample_dims)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QulX66d_VGpB"
      },
      "source": [
        "# Show shape of the reshaped dataset\n",
        "print(\"Training matrix shape:\", X_train_rs.shape)\n",
        "print(\"Testing matrix shape:\", X_testval_rs.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNYgr-3QVJ79"
      },
      "source": [
        "# Convert dtype to float32\n",
        "X_train_fl = X_train_rs.astype('float32')\n",
        "X_testval_fl = X_testval_rs.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSuUhzszVSk0"
      },
      "source": [
        "# Show dtype of the dataset\n",
        "print(\"Training matrix dtype:\", X_train_fl.dtype)\n",
        "print(\"Testing matrix dtype:\", X_testval_fl.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwuZgXTKVXUo"
      },
      "source": [
        "# Change the range of pixels from [0 255] to [0 1]\n",
        "X_train_fl /= 255\n",
        "X_testval_fl /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gniB10xqVZsj"
      },
      "source": [
        "# Show the range of pixels\n",
        "print(\"Training matrix range:\", \"[\", X_train_fl.min(), \",\", X_train_fl.max(), \"]\")\n",
        "print(\"Testing matrix range:\", \"[\", X_testval_fl.min(), \",\", X_testval_fl.max(), \"]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj74QnR4Vbt1"
      },
      "source": [
        "# Import dependence for one-hot encoding\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nTRJ7yeVeN3"
      },
      "source": [
        "# One-hot encoding of labels\n",
        "onehot_enc = OneHotEncoder()\n",
        "y_train_oh = onehot_enc.fit_transform(y_train.reshape(train_samples, 1)).toarray()\n",
        "y_testval_oh = onehot_enc.fit_transform(y_testval.reshape(testval_samples, 1)).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry7H5BvPVl6D"
      },
      "source": [
        "# Show one-hot encoded labels shape\n",
        "print(\"Training one-hot encoded labels shape:\", y_train_oh.shape)\n",
        "print(\"Testing one-hot encoded labels shape:\", y_testval_oh.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PoZUM_sVoi6"
      },
      "source": [
        "# Divide testval in test and validation partitions\n",
        "samples_test_nb = int(X_testval.shape[0]/2)\n",
        "X_val = X_testval_fl[:samples_test_nb]\n",
        "y_val = y_testval_oh[:samples_test_nb]\n",
        "X_test = X_testval_fl[samples_test_nb:]\n",
        "y_test = y_testval_oh[samples_test_nb:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofgM7brWVsN1"
      },
      "source": [
        "# Show shapes of test and validation partitions\n",
        "print(\"Validation matrix shape:\", X_val.shape)\n",
        "print(\"Testing matrix shape:\", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h8SaYLOVt_t"
      },
      "source": [
        "# Import dependencies for network dessign\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-g22PZOVwj0"
      },
      "source": [
        "# Define the model\n",
        "input_layer = Input(shape=(X_train_fl.shape[1],))\n",
        "hidden_layer_1= Dense(128, activation='relu')(input_layer)\n",
        "hidden_layer_2= Dense(256, activation='relu')(hidden_layer_1)\n",
        "hidden_layer_3 = Dense(256, activation='relu')(hidden_layer_2)\n",
        "output_layer = Dense(10, activation='softmax')(hidden_layer_3)\n",
        "model= Model(inputs=input_layer, outputs=output_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzt4Th7iV1tF"
      },
      "source": [
        "# Show a summary of the model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFM5py6aV4DM"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a6viyT4V_9_"
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_fl, y_train_oh, epochs=20, batch_size=128,\n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAR15yICV6hU"
      },
      "source": [
        "# Plot training and validation accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.ylim(0, 1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OM3GB9SV86n"
      },
      "source": [
        "# Plot training and test loss\n",
        "plt.plot(history.history['loss']) \n",
        "plt.plot(history.history['val_loss']) \n",
        "plt.title('Model loss') \n",
        "plt.ylabel('Loss') \n",
        "plt.xlabel('Epoch') \n",
        "plt.legend(['Train', 'Val'], loc='upper left') \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r7vK8pKXBuT"
      },
      "source": [
        "# Obtain metrics in the test partition\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwOdbB39XOG4"
      },
      "source": [
        "# Predict test samples post-process them\n",
        "predicted_classes = model.predict(X_test)\n",
        "predicted_classes = np.round(predicted_classes)\n",
        "predicted_classes = np.argmax(predicted_classes, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_pqIncEXRIe"
      },
      "source": [
        "# Convert test labels to scalars\n",
        "y_test_scalar = np.argmax(y_test, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7HxUM2vXT1X"
      },
      "source": [
        "# Obtain test samples correctly predicted\n",
        "correct_indices = np.nonzero(predicted_classes == y_test_scalar)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olMalvPDXV0O"
      },
      "source": [
        "# Obtain test samples incorrectly predicted\n",
        "incorrect_indices = np.nonzero(predicted_classes != y_test_scalar)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8JakvkmXX_d"
      },
      "source": [
        "# Show some correctly classified samples\n",
        "plt.figure()\n",
        "for i, correct in enumerate(correct_indices[:9]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_test[correct].reshape(32,32,3), cmap='gray', \n",
        "               interpolation='none')\n",
        "    predicted_str = class_to_string(predicted_classes[correct])\n",
        "    y_test_str = class_to_string(y_test_scalar[correct])\n",
        "    plt.title(\"Predicted: \" + predicted_str + \", Class: \" + y_test_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c39Q3umiXaSw"
      },
      "source": [
        "# Show some incorrectly classified samples\n",
        "plt.figure()\n",
        "for i, incorrect in enumerate(incorrect_indices[:9]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_test[incorrect].reshape(32,32,3), cmap='gray', \n",
        "               interpolation='none')\n",
        "    predicted_str = class_to_string(predicted_classes[incorrect])\n",
        "    y_test_str = class_to_string(y_test_scalar[incorrect])\n",
        "    plt.title(\"Predicted: \" + predicted_str + \", Class: \" + y_test_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPyhu056aSnb"
      },
      "source": [
        "# 2. CIFAR10 with Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TXqYiTqbQz2"
      },
      "source": [
        "# Show the shape of the data partitions\n",
        "print(\"X_train original shape:\", X_train.shape)\n",
        "print(\"y_train one-hot shape:\", y_train_oh.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ7MAVcEby8D"
      },
      "source": [
        "There is no need to reshape since CNN are designed to handle images, what we need to redo is the following:\n",
        "\n",
        "\n",
        "1.   Change range to [0 1]\n",
        "2.   Split data in validation and test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ5vh3g8Xh_j"
      },
      "source": [
        "# Change the range of pixels from [0 255] to [0 1]\n",
        "X_train_fl2 = X_train.astype('float32')\n",
        "X_testval_fl2 = X_testval.astype('float32')\n",
        "X_train_fl2 /= 255\n",
        "X_testval_fl2 /= 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utt7JxFpc4EN"
      },
      "source": [
        "# Show the range of pixels\n",
        "print(\"Training matrix range:\", \"[\", X_train_fl2.min(), \",\", \n",
        "      X_train_fl2.max(), \"]\")\n",
        "print(\"Testing matrix range:\", \"[\", X_testval_fl2.min(), \",\", \n",
        "      X_testval_fl2.max(), \"]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UNzsqWIdECS"
      },
      "source": [
        "# Divide testval in test and validation partitions\n",
        "samples_test_nb = int(X_testval.shape[0]/2)\n",
        "X_val2 = X_testval_fl2[:samples_test_nb]\n",
        "y_val2 = y_testval_oh[:samples_test_nb]\n",
        "X_test2 = X_testval_fl2[samples_test_nb:]\n",
        "y_test2 = y_testval_oh[samples_test_nb:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KOeKNSTdx1L"
      },
      "source": [
        "# Show shapes of test and validation partitions\n",
        "print(\"Validation matrix shape:\", X_val2.shape)\n",
        "print(\"Testing matrix shape:\", X_test2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LC-Pnzhd9Pa"
      },
      "source": [
        "# Import depence for CNN\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEo9D6q7d2eq"
      },
      "source": [
        "# Define the model\n",
        "input_layer = Input(shape=(X_train.shape[1],X_train.shape[2], X_train.shape[3]))\n",
        "conv_layer_1 = Conv2D(filters=8, kernel_size=(3, 3), activation='relu')(input_layer)\n",
        "maxpool_layer_1 = MaxPool2D(pool_size=(2, 2))(conv_layer_1)\n",
        "conv_layer_2 = Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(maxpool_layer_1)\n",
        "maxpool_layer_2 = MaxPool2D(pool_size=(2, 2))(conv_layer_2)\n",
        "conv_layer_3 = Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(maxpool_layer_2)\n",
        "flatten_layer = Flatten()(conv_layer_3)\n",
        "dense_layer = Dense(128, activation='relu')(flatten_layer)\n",
        "output_layer = Dense(10, activation='softmax')(dense_layer)\n",
        "model= Model(inputs=input_layer, outputs=output_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpMDNZfaerOy"
      },
      "source": [
        "# Show summary of the model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5JZKthleyeW"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvJH3nNCe_1F"
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_fl2, y_train_oh, epochs=20, batch_size=128,\n",
        "                    validation_data=(X_val2, y_val2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grx84jt5gYD_"
      },
      "source": [
        "# Plot training and validation accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.ylim(0, 1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEg8qwlKgYEI"
      },
      "source": [
        "# Plot training and test loss\n",
        "plt.plot(history.history['loss']) \n",
        "plt.plot(history.history['val_loss']) \n",
        "plt.title('Model loss') \n",
        "plt.ylabel('Loss') \n",
        "plt.xlabel('Epoch') \n",
        "plt.legend(['Train', 'Val'], loc='upper left') \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1T5qx1sgYEJ"
      },
      "source": [
        "# Obtain metrics in the test partition\n",
        "score = model.evaluate(X_test2, y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXbIsR89gYEK"
      },
      "source": [
        "# Predict test samples post-process them\n",
        "predicted_classes = model.predict(X_test2)\n",
        "predicted_classes = np.round(predicted_classes)\n",
        "predicted_classes = np.argmax(predicted_classes, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn4yCbKagYEM"
      },
      "source": [
        "# Convert test labels to scalars\n",
        "y_test_scalar = np.argmax(y_test, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYPXrp2ogYEO"
      },
      "source": [
        "# Obtain test samples correctly predicted\n",
        "correct_indices = np.nonzero(predicted_classes == y_test_scalar)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhZKBnrkgYEP"
      },
      "source": [
        "# Obtain test samples incorrectly predicted\n",
        "incorrect_indices = np.nonzero(predicted_classes != y_test_scalar)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3FB9VqRgYEQ"
      },
      "source": [
        "# Show some correctly classified samples\n",
        "plt.figure()\n",
        "for i, correct in enumerate(correct_indices[:9]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_test[correct].reshape(32,32,3), cmap='gray', \n",
        "               interpolation='none')\n",
        "    predicted_str = class_to_string(predicted_classes[correct])\n",
        "    y_test_str = class_to_string(y_test_scalar[correct])\n",
        "    plt.title(\"Predicted: \" + predicted_str + \", Class: \" + y_test_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtLv5hPJgYER"
      },
      "source": [
        "# Show some incorrectly classified samples\n",
        "plt.figure()\n",
        "for i, incorrect in enumerate(incorrect_indices[:9]):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(X_test[incorrect].reshape(32,32,3), cmap='gray', \n",
        "               interpolation='none')\n",
        "    predicted_str = class_to_string(predicted_classes[incorrect])\n",
        "    y_test_str = class_to_string(y_test_scalar[incorrect])\n",
        "    plt.title(\"Predicted: \" + predicted_str + \", Class: \" + y_test_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3RvIf7qhmva"
      },
      "source": [
        "# Exercise 1: Train the CNN model with 50 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qYk4wSahwAx"
      },
      "source": [
        "# Train the model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOhbXao4kl08"
      },
      "source": [
        "# Exercise 2: Double the number of filters in each Conv layer and re-train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttWTJTtPkkZP"
      },
      "source": [
        "# Define the model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvMhAQg9k_6e"
      },
      "source": [
        "# Show summary of the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JowNb8ik_6l"
      },
      "source": [
        "# Compile the model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moiZ65ckk_6n"
      },
      "source": [
        "# Train the model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVwZ2bqEhMAy"
      },
      "source": [
        "# Exercise 3: Train a CNN with 2 Conv Blocks before each Maxpooling hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcxpCFDhiEoc"
      },
      "source": [
        "# Define the model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31KpM2eziEoi"
      },
      "source": [
        "# Show summary of the model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In35PmJ0iEok"
      },
      "source": [
        "# Compile the model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "095yzeLgiEol"
      },
      "source": [
        "# Train the model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ajvdcePn0dM"
      },
      "source": [
        "# Exercise 4: Experiment to improve results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-0NfLYIn4d1"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}