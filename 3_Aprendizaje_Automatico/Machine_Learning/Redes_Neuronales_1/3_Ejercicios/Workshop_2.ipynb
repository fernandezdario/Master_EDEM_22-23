{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Workshop 2: Handwritten digit classification with PyTorch\n",
        "In this workshop we will learn how to train a neural network with images \n",
        "as input to classify hand-written digits\n",
        "([info of the data](http://yann.lecun.com/exdb/mnist/)). The main blocks of the workshop are:\n",
        "\n",
        "1. Get the data from PyTorch repository and visualize it.\n",
        "2. Pre-process the data.\n",
        "3. Design the network.\n",
        "4. Train the network.\n",
        "5. Evaluate the model."
      ],
      "metadata": {
        "id": "8nDKkFNROcyh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Get the data from PyTorch repository and visualize it."
      ],
      "metadata": {
        "id": "zGT8jYviOh_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsummary import summary\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "XpiiImoMO3px"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seed for reproducibility\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "aiNE3lYRO3sV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True)"
      ],
      "metadata": {
        "id": "J4hR3DQgO3vC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "id": "JMqtEH0FO3xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "id": "TJ2memw0PUsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0][0].show()"
      ],
      "metadata": {
        "id": "bOgihSAFPbT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_array = np.array(train_dataset[0][0])\n",
        "print(\"Sample shape:\", sample_array.shape)\n",
        "print(\"Sample min value:\", sample_array.min())\n",
        "print(\"Sample max value:\", sample_array.max())"
      ],
      "metadata": {
        "id": "YCVKE7ABQQxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset"
      ],
      "metadata": {
        "id": "avxdZ7MfO31K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset[0]"
      ],
      "metadata": {
        "id": "EYHSIsUnPmxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset[0][0].show()"
      ],
      "metadata": {
        "id": "Los9fm0fPotz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Pre-process the data."
      ],
      "metadata": {
        "id": "pwN15HgCOqHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "# Split the test set into validation and test sets\n",
        "valid_dataset, test_dataset = torch.utils.data.random_split(test_dataset, [5000, 5000])\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "lv3_v7TiTeos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = next(iter(train_loader))\n",
        "print(\"Sample shape:\", images.shape)\n",
        "print(\"Sample min value:\", images.min())\n",
        "print(\"Sample max value:\", images.max())"
      ],
      "metadata": {
        "id": "Gy4zlU_OVcvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dependence for visualization of images\n",
        "plt.rcParams['figure.figsize'] = (10,10)  # Configure figure size for \n",
        "                                          # appropriate visualization"
      ],
      "metadata": {
        "id": "1ue573nPU73F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the images in a 3x3 grid\n",
        "nrows = 3\n",
        "ncols = 3\n",
        "nsamples = nrows*ncols\n",
        "for i in range(nsamples):\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.imshow(images[i, 0, :, :], cmap='gray', interpolation='none')\n",
        "    plt.title(\"Class {}\".format(labels[i]))"
      ],
      "metadata": {
        "id": "38GGWDGYTjLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Design the network."
      ],
      "metadata": {
        "id": "ELzY49vBOqKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 32)\n",
        "        self.fc2 = nn.Linear(32, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.softmax(self.fc2(x), dim=1)\n",
        "        return x\n",
        "\n",
        "model = Net()"
      ],
      "metadata": {
        "id": "n469-4MfWrWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (1, 28, 28))"
      ],
      "metadata": {
        "id": "3m2SwbvKYPiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "ZYbemSz8XIF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Train the network."
      ],
      "metadata": {
        "id": "68YkMwOaOqNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(y_pred, y_true):\n",
        "    \"\"\"Calculate the accuracy between predicted and true labels\"\"\"\n",
        "    _, y_pred = torch.max(y_pred, dim=1)\n",
        "    correct = torch.sum(y_pred == y_true).float()\n",
        "    acc = correct / len(y_true)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "JJLCMQHjjaz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "train_loss_history = []\n",
        "valid_loss_history = []\n",
        "train_accuracy_history = []\n",
        "valid_accuracy_history = []\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        # Clear gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Move images and labels to device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "    # Calculate accuracy\n",
        "    train_loss = 0\n",
        "    valid_loss = 0\n",
        "    train_accuracy = 0\n",
        "    valid_accuracy = 0\n",
        "\n",
        "    # Turn off gradients for validation to speed up inference\n",
        "    with torch.no_grad():\n",
        "        for images, labels in train_loader:\n",
        "\n",
        "            # Move images and labels to device\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "            # Forward pass\n",
        "            output = model(images)\n",
        "\n",
        "            # Calculate loss\n",
        "            train_loss += criterion(output, labels)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            train_accuracy += get_accuracy(output, labels)\n",
        "        \n",
        "        train_loss_history.append(train_loss.cpu().numpy() / len(train_loader))\n",
        "        train_accuracy_history.append(train_accuracy.cpu().numpy() / len(train_loader))\n",
        "\n",
        "        for images, labels in valid_loader:\n",
        "\n",
        "            # Move images and labels to device\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "            # Forward pass\n",
        "            output = model(images)\n",
        "\n",
        "            # Calculate loss\n",
        "            valid_loss += criterion(output, labels)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            valid_accuracy += get_accuracy(output, labels)\n",
        "        \n",
        "        valid_loss_history.append(valid_loss.cpu().numpy() / len(valid_loader))\n",
        "        valid_accuracy_history.append(valid_accuracy.cpu().numpy() / len(valid_loader))\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
        "              f\"Train loss: {train_loss/len(train_loader):.3f} | \"\n",
        "              f\"Train accuracy: {train_accuracy/len(train_loader):.3f} | \"\n",
        "              f\"Valid loss: {valid_loss/len(valid_loader):.3f} | \"\n",
        "              f\"Valid accuracy: {valid_accuracy/len(valid_loader):.3f}\")"
      ],
      "metadata": {
        "id": "TE_6nPVfXYA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation accuracy\n",
        "plt.plot(train_accuracy_history)\n",
        "plt.plot(valid_accuracy_history)\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zUkSdhbrSfjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation accuracy\n",
        "plt.plot(train_loss_history)\n",
        "plt.plot(valid_loss_history)\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SOuwjFRPTJR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Evaluate the model."
      ],
      "metadata": {
        "id": "Ohk85u8QOqYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics in the test partition\n",
        "test_loss = 0\n",
        "test_accuracy = 0\n",
        "for images, labels in test_loader:\n",
        "\n",
        "    # Move images and labels to device\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    \n",
        "    # Forward pass\n",
        "    output = model(images)\n",
        "\n",
        "    # Calculate loss\n",
        "    test_loss += criterion(output, labels)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    test_accuracy += get_accuracy(output, labels)\n",
        "print(\"Test loss:\", test_loss / len(test_loader))\n",
        "print(\"Test accuracy:\", test_accuracy / len(test_loader))"
      ],
      "metadata": {
        "id": "OafHOLxsSeeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFikgbMtE7vv"
      },
      "source": [
        "# Exercise 1: Create a new model with 512 neurons in the hidden layer and repeat the process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHsnnITjE7Bi"
      },
      "source": [
        "# Design the model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecq4qZiRG1r2"
      },
      "source": [
        "# Show summary of the model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n"
      ],
      "metadata": {
        "id": "JmE-8AtDZdA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoEN_hmFGa01"
      },
      "source": [
        "# Train the model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7be6fqJwIXIJ"
      },
      "source": [
        "# Obtain metrics in the test partition\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqlE4Fn6Fi1G"
      },
      "source": [
        "# Exercise 2: Add a hidden layer with 512 neurons to the model of exercise 1 and repeat the process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmP3tEOOZ_Hh"
      },
      "source": [
        "# Design the model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rARt_5FOZ_Hq"
      },
      "source": [
        "# Show summary of the model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n"
      ],
      "metadata": {
        "id": "Pl4uwKNLZ_Hr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqU47hrwZ_Hr"
      },
      "source": [
        "# Train the model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGcrukkIZ_Hr"
      },
      "source": [
        "# Obtain metrics in the test partition\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}